# Drill sub-section
drill:
  # Name of the Drill cluster. Also used to create the ZK node for the Drill cluster
  id: drillcluster1
  # Number of Drill Pods which are launched in parallel and join to form a Drill Cluster
  count: 2
  # Total heap memory for each Drill pod
  heapMemory: 8G
  # Total direct memory for each Drill pod
  directMemory: 10G
  # Total CPU for each Drill pod
  cpu: 4000m
    # Drill image pull secrets
  imagePullSecrets:
    - name: image-pull-sec
  # Drill image with tag
  image: serviceacrps.azurecr.io/apache-drill:0.1.4
  # Drill image pull policy
  # * IfNotPresent - If the image is not cached on the device
  # * Always         - Will always try to fetch the newest image
  # * Never          - Will not try to fetch an image - if image is not present on the machine startup fails
  imagePullPolicy: IfNotPresent
  # Drill's HTTP port
  httpPort: 8047
  # User Server port. The Bit Server Port and Data Server ports are +1 and +2
  userServerPort: 31010
  # The type of the service
  serviceType: ClusterIP
  # Periodically, a diagnostic is performed to check the 'liveness' of a Drill container
  # The livenessProbe indicates whether the Container is running. If the probe fails, it's restarted
  livenessProbe:
    exec:
      # The absolute path of the liveness probe script on the pod
      command:
        - sh
        - -c
        - /opt/drill/bin/isLive.sh
    # Number of seconds after the container has started before probes are initiated
    # (to account for time taken by Drillbit process to start)
    initialDelaySeconds: 10
    # Number of seconds after which to retry probes
    periodSeconds: 30
    # Number of seconds after which probes time out
    timeoutSeconds: 10
    # Number of retries in case of probe failures
    failureThreshold: 10
  # Periodically, a diagnostic is performed to check the 'readiness' of a Drill container
  # The readinessProbe indicates whether the Container is ready to service requests. If the probe fails,
  # the Pod's IP address is removed from the endpoints of all Services that match the Pod
  readinessProbe:
    exec:
      # The absolute path of the readiness probe script on the pod
      command:
        - sh
        - -c
        - /opt/drill/bin/isReady.sh
    # Number of seconds after the container has started before probes are initiated
    # (to account for time taken by Drillbit process to start)
    initialDelaySeconds: 10
    # Number of seconds after which to retry probes
    periodSeconds: 30
    # Number of seconds after which probes time out
    timeoutSeconds: 10
    # Number of retries in case of probe failures
    failureThreshold: 5
  # Lifecycle hooks
  lifecycle:
    # During a scale down of the Drill Cluster, a preStop hook is executed on the pod replicas
    # that are to be brought down, which instructs the Drillbit process to gracefully shutdown
    preStop:
      exec:
        # The absolute path of the preStop script on the pod
        command:
          - sh
          - -c
          - /opt/drill/bin/preStop.sh
  # Number of seconds after which pods are forcefully killed
  # Note: Lower values may cause running queries to fail
  terminationGracePeriodSeconds: 60
  # Drill Configuration can be overridden by mounting them on each Drill container.
  # Edit the files in `conf` with your custom configurations
  # Use `conf/createCM.sh` to create the ConfigMap
  drillConf:
    # Flag to turn-on / turn-off this option
    override: false
    # Name of the ConfigMap with Drill config files
    configMapName: drill-config-cm
  # The size of the Drill cluster (number of Drill Pod replicas) can be autoscaled
  # With higher CPU utilization, more drill-bits are added automatically. And as the load goes down,
  # so do the number of drill-bits in the Drill Cluster (by gracefully shutting down)
  autoscale:
    # Flag to turn-on / turn-off this option
    enabled: false
    # Maximum number of Drill Pods
    maxCount: 4
    # Target CPU Utilization Percentage
    cpuThreshold: 75
  # The rules for selecting a node to run on
  nodeSelectorTerms:
    - matchExpressions:
      - key: agentpool
        operator: In
        values:
        - worker

  volumeMounts:
    - name: drill-config-override
      mountPath: /opt/drill/conf/storage-plugins-override.conf
      subPath: storage-plugins-override.conf
    - name: drill-cm
      mountPath: /opt/drill/conf

  volumes:
    - name: drill-config-override
      secret:
        secretName: drill-storage-override-conf
    - name: drill-cm
      configMap:
        name: drill-cm
        items:
          - key: drill-override.conf
            path: drill-override.conf
          - key: zoo.cfg
            path: zoo.cfg

# ZooKeeper sub-section
zookeeper:
  # Name of the ZooKeeper quorum (currently single-node configuration only)
  id: zk
  # Total memory for each ZooKeeper pod
  memory: 2Gi
  # Total CPU for each ZooKeeper pod
  cpu: 500m
  # Drill image pull secrets
  imagePullSecrets:
    - name: image-pull-sec
  # ZooKeeper image with tag
  image: serviceacrps.azurecr.io/zookeeper:0.1.4
  # ZooKeeper image with tag
  # * IfNotPresent - If the image is not cached on the device
  # * Always         - Will always try to fetch the newest image
  # * Never          - Will not try to fetch an image - if image is not present on the machine startup fails
  imagePullPolicy: IfNotPresent

janus:
  enabled: true
  host: drill.{{ .Values.ingress.host }}
  certmanagerIssuer:
    name: {{ .Values.ingress.certmanagerissuer | quote }}
    kind: ClusterIssuer

  ingressRoutes:
    - name: apache-drill-{{ .Values.nameSuffix }}
      entryPoints:
        - websecure
      routes:
        - kind: Rule
          match:
          services:
            - name: drill-service
              port: 8047
          middlewares:
            - name: auth
              namespace: networking
      certificate:
        enabled: true

lethe:
  enabled: true
  secretStores:
    - name: vault-backend
      providers:
        vault:
          server: "{{ .Values.vaultServer }}"
          path: "apache-drill"
          version: "v2"
          auth:
            # Authenticate against Vault using a Kubernetes ServiceAccount
            # token stored in a Secret.
            # https://www.vaultproject.io/docs/auth/kubernetes
            kubernetes:
              # Path where the Kubernetes authentication backend is mounted in Vault
              mountPath: "{{ template "helper.name" (dict "context" . "name" "kubernetes") }}"
              # A required field containing the Vault Role to assume.
              role: "apache-drill-reader"
  secrets:
    - name: drill-storage-override-conf
      secretStore:
        backend: vault-backend
        kind: SecretStore
      target:
        name: drill-storage-override-conf
        template:
          templateFrom:
            - configMap:
                name: drill-es-tpl-cm
                items:
                  - key: storage-plugins-override.conf
      dataFrom:
        - key: creds